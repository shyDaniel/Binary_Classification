{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generative_probabilistic_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSxvut8j5HR+NqszpT7xkZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shyDaniel/Binary_Classification/blob/master/Generative_probabilistic_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eGd2SLMLFia",
        "colab_type": "text"
      },
      "source": [
        "## **GENERATIVE PROBABILISTIC MODEL**\n",
        "\n",
        "Kaggle: https://www.kaggle.com/c/ml2020spring-hw2/overview\n",
        "\n",
        "Hanyu Song 03/24/2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAbtPDhVJcxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "92b2a1ef-5a56-4f56-cf73-f9f1c096f902"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "\n",
        "!gdown --id '1JuYMZyt0-jwVIwiVs-mgQE8i_O3QUyT3' --output Xtrain.zip\n",
        "!gdown --id '1iVZaPjgTmwwp683hV8cw-7Q2r3AunasO' --output Xtest.zip\n",
        "!gdown --id '1C0eGiL5azG49lnS45LxCdbrY0Ce4nNU2'\n",
        "!unzip Xtrain.zip\n",
        "!unzip Xtest.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JuYMZyt0-jwVIwiVs-mgQE8i_O3QUyT3\n",
            "To: /content/Xtrain.zip\n",
            "2.79MB [00:00, 83.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iVZaPjgTmwwp683hV8cw-7Q2r3AunasO\n",
            "To: /content/Xtest.zip\n",
            "100% 1.42M/1.42M [00:00<00:00, 90.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1C0eGiL5azG49lnS45LxCdbrY0Ce4nNU2\n",
            "To: /content/Y_train\n",
            "100% 423k/423k [00:00<00:00, 56.8MB/s]\n",
            "Archive:  Xtrain.zip\n",
            "  inflating: X_train                 \n",
            "Archive:  Xtest.zip\n",
            "  inflating: X_test                  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzSpAxsrLFFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_fpath = '/content/X_train'\n",
        "Y_train_fpath = '/content/Y_train'\n",
        "X_test_fpath = '/content/X_test'\n",
        "\n",
        "with open(X_train_fpath) as f:\n",
        "    next(f)\n",
        "    X_train = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)\n",
        "with open(Y_train_fpath) as f:\n",
        "    next(f)\n",
        "    Y_train = np.array([line.strip('\\n').split(',')[1] for line in f], dtype = float)\n",
        "with open(X_test_fpath) as f:\n",
        "    next(f)\n",
        "    X_test = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTXDHRUSLfFN",
        "colab_type": "text"
      },
      "source": [
        "**NORMALIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lQl8zcELcex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _normalize(X, train = True, specified_column = None, X_mean = None, X_std = None):\n",
        "    # This function normalizes specific columns of X.\n",
        "    # The mean and standard variance of training data will be reused when processing testing data.\n",
        "    #\n",
        "    # Arguments:\n",
        "    #     X: data to be processed\n",
        "    #     train: 'True' when processing training data, 'False' for testing data\n",
        "    #     specific_column: indexes of the columns that will be normalized. If 'None', all columns\n",
        "    #         will be normalized.\n",
        "    #     X_mean: mean value of training data, used when train = 'False'\n",
        "    #     X_std: standard deviation of training data, used when train = 'False'\n",
        "    # Outputs:\n",
        "    #     X: normalized data\n",
        "    #     X_mean: computed mean value of training data\n",
        "    #     X_std: computed standard deviation of training data\n",
        "\n",
        "    if specified_column == None:\n",
        "        specified_column = np.arange(X.shape[1])\n",
        "    if train:\n",
        "        X_mean = np.mean(X[:, specified_column] ,0).reshape(1, -1)\n",
        "        X_std  = np.std(X[:, specified_column], 0).reshape(1, -1)\n",
        "\n",
        "    X[:,specified_column] = (X[:, specified_column] - X_mean) / (X_std + 1e-8)\n",
        "     \n",
        "    return X, X_mean, X_std\n",
        "\n",
        "def _predict(X, w, b):\n",
        "    # This function returns a truth value prediction for each row of X \n",
        "    # by rounding the result of logistic regression function.\n",
        "    return np.round(_f(X, w, b)).astype(np.int)\n",
        "\n",
        "def _f(X, w, b):\n",
        "    # This is the logistic regression function, parameterized by w and b\n",
        "    #\n",
        "    # Arguements:\n",
        "    #     X: input data, shape = [batch_size, data_dimension]\n",
        "    #     w: weight vector, shape = [data_dimension, ]\n",
        "    #     b: bias, scalar\n",
        "    # Output:\n",
        "    #     predicted probability of each row of X being positively labeled, shape = [batch_size, ]\n",
        "    return _sigmoid(np.matmul(X, w) + b)\n",
        "\n",
        "def _sigmoid(z):\n",
        "    # Sigmoid function can be used to calculate probability.\n",
        "    # To avoid overflow, minimum/maximum output value is set.\n",
        "    return np.clip(1 / (1.0 + np.exp(-z)), 1e-8, 1 - (1e-8))\n",
        "\n",
        "def _accuracy(Y_pred, Y_label):\n",
        "    # This function calculates prediction accuracy\n",
        "    acc = 1 - np.mean(np.abs(Y_pred - Y_label))\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcESeOQeLec6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize training and testing data\n",
        "X_train, X_mean, X_std = _normalize(X_train, train = True)\n",
        "X_test, _, _= _normalize(X_test, train = False, specified_column = None, X_mean = X_mean, X_std = X_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDOTiTRDNAPd",
        "colab_type": "text"
      },
      "source": [
        "**Mean and Covariance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L39UxRTTM6Ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute in-class mean\n",
        "X_train_0 = np.array([x for x, y in zip(X_train, Y_train) if y == 0])\n",
        "X_train_1 = np.array([x for x, y in zip(X_train, Y_train) if y == 1])\n",
        "\n",
        "mean_0 = np.mean(X_train_0, axis = 0)\n",
        "mean_1 = np.mean(X_train_1, axis = 0)  \n",
        "\n",
        "# Compute in-class covariance\n",
        "data_dim = X_train.shape[1]\n",
        "cov_0 = np.zeros((data_dim, data_dim))\n",
        "cov_1 = np.zeros((data_dim, data_dim))\n",
        "\n",
        "for x in X_train_0:\n",
        "    cov_0 += np.dot(np.transpose([x - mean_0]), [x - mean_0]) / X_train_0.shape[0]\n",
        "for x in X_train_1:\n",
        "    cov_1 += np.dot(np.transpose([x - mean_1]), [x - mean_1]) / X_train_1.shape[0]\n",
        "\n",
        "# Shared covariance is taken as a weighted average of individual in-class covariance.\n",
        "cov = (cov_0 * X_train_0.shape[0] + cov_1 * X_train_1.shape[0]) / (X_train_0.shape[0] + X_train_1.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5qcASSoOu_A",
        "colab_type": "text"
      },
      "source": [
        "**Computing weights and bias**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGPVq791OsvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ef6e4c0-fd17-407b-95a8-89d03da43c7d"
      },
      "source": [
        "# Compute inverse of covariance matrix.\n",
        "# Since covariance matrix may be nearly singular, np.linalg.inv() may give a large numerical error.\n",
        "# Via SVD decomposition, one can get matrix inverse efficiently and accurately.\n",
        "u, s, v = np.linalg.svd(cov, full_matrices=False)\n",
        "inv = np.dot(v.T * 1 / s, u.T)\n",
        "\n",
        "# Directly compute weights and bias\n",
        "w = np.dot(inv, mean_0 - mean_1)\n",
        "b =  (-0.5) * np.dot(mean_0, np.dot(inv, mean_0)) + 0.5 * np.dot(mean_1, np.dot(inv, mean_1))\\\n",
        "    + np.log(float(X_train_0.shape[0]) / X_train_1.shape[0]) \n",
        "\n",
        "# Compute accuracy on training set\n",
        "Y_train_pred = 1 - _predict(X_train, w, b)\n",
        "print('Training accuracy: {}'.format(_accuracy(Y_train_pred, Y_train)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.8719219994102034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH9nFrs7X2bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('weights.npy', w)\n",
        "np.save('cons.npy',b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE0a9FOcO0jH",
        "colab_type": "text"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZVGdRboO2U2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict testing labels\n",
        "weights = np.load('weights.npy')\n",
        "cons = np.load('cons.npy')\n",
        "predictions = 1 - _predict(X_test, w, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EEOWDO9eUNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(np.empty((predictions.shape[0], 2)), index = np.arange(predictions.shape[0]) + 1, columns = ['id', 'label'], dtype = int)\n",
        "for i in range (predictions.shape[0]):\n",
        "  df.iloc[i, 0] = i\n",
        "  df.iloc[i, 1] = predictions[i]\n",
        "df.to_csv('submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}